---
title: "Medical Cost Analysis"
author: "Janick Reales"
date: "11/4/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, comment = "")
```
# Medical Cost Analysis
 
The data used in this analysis was taken from [kaggle](https://www.kaggle.com/usdot/pipeline-accidents) and contains a series of data to predict the Indivial Medical Cost billed by health insurance.

The columns within the dataset are the following:

* age: age of primary beneficiary
* sex: insurance contractor gender, female, male
* bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9
* children: Number of children covered by health insurance / Number of dependents
* smoker: Smoking
* region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.
* charges: Individual medical costs billed by health insurance

In this notebook we aim to perform an exploratory data analysis in order to describe the main characteristics of our data and then to train and fit a Linear Regression model to predict medical costs with the highest accuracy as possible.

First, we have to import the libraries needed and the database.


```{r echo=FALSE, include=FALSE}
library(dplyr)
library(ggplot2)
library(plotly)
library(kableExtra)
library(gridExtra)
```


```{r echo=FALSE}
## loading data
medical_cost <- read.csv("insurance.csv", header=TRUE, sep=',', encoding="UTF-8")

## Information
str(medical_cost)
```  

As we observe, the dataframe contains 1338 observations and 7 variables. Now, let's see if we have missing variables into our columns.  

```{r}
## function to count missing values
Na_Count <- function(feature) {
  sum(is.na(feature))
}

## applying to the data
apply(medical_cost, 2, Na_Count)
```  

There are no missing values into the data frame. The next step is to convert categorical columns ("sex", "children", "smoker", "region") into factor, so we can used then later for drawing some plots and to train the model.  

```{r}
## to factor
medical_cost$sex <- as.factor(medical_cost$sex)
medical_cost$children <- as.factor(medical_cost$children)
medical_cost$smoker <- as.factor(medical_cost$smoker)
medical_cost$region <- as.factor(medical_cost$region)

## 
head(medical_cost)
```  

Now, let's get some statistics about the data.  

```{r}
## summary
summary(medical_cost)
```  

* The median and the mean *age* are equal, telling us that the data is not skewed.  
* The same conclusion for the *bmi* variable.  
* We have almost the same amount of data for women and man. The opposite for the *smoker* variable, for what the data is unbalanced, having far more non smoker users.  
* Users with no children prevail in the data set.  
* We have almost the same amount of users by each region.  
* For the *charges* variable, the mean is higher than the median. This tells us that the distribution for the charges variable is right skewed. We can also observe that the maximun value is is far from the 3rd quartile, so we may have outliers.  


### **Exploratory Data Analysis**  

First of all, I want to see the correlation between the continuous features (age and bmi), with  the target variable (charges), since it is important to  know this values to figure out how linear is that relationship.  

We have to get the correlation matrix and then melt the data to make possible drawing a heatmap with `ggplot2`.  


```{r}
library(reshape)
cormat <- cor(medical_cost[c("age","bmi", "charges")])

## melting
melted_data <- melt(cormat)
head(melted_data)
```  

```{r}
## plot
g <- ggplot(data = melted_data, aes(x=X1, y=X2, fill=value)) + geom_tile()
g <- g + labs(x="", y="") + labs(title="Correlation heatmap")
g <- g + geom_text(aes(X1,X2, label=round(value,2)), color="white", size=4)
g
```  

Here we see that the linear correlation between our variables is low, so we can say that the real relationship is not linear. I will explore that later in the notebook.  

For now, let's build a series of plot that allow to understand the behavior of the charges relative to every variable in the dataset.  


* ##### **Age vs Charges**  

We already know that the correlation between the variables is not that linear, but it is a good idea to explore the distribution of charges for those ones whose age is above and below the mean value.  

```{r}
## adding the discretization
medical_age <- medical_cost
medical_age$aboveMean<- ifelse(medical_age$age > mean(medical_age$age), "above", "below")
medical_age$aboveMean <- as.factor(medical_age$aboveMean)

## plot
ghist <- ggplot(medical_age, aes(x=charges))+geom_histogram(aes(color=aboveMean, fill=aboveMean))
ghist <- ghist + facet_grid(aboveMean~.) + labs(y="", title="Charges Distribution")
ghist
```  

People older than 39 years tend to spend more money in medical insurances. Both histogram show a multimodal behavior. In both cases we observe charges greater than USD 60000.  

Now, lets plot a scatter plot of charges vs age vs sex.  

```{r}
## scatter
gscat <- ggplot(medical_cost, aes(age, charges, color=sex)) + geom_point()
gscat <- gscat + labs(title = "Age vs Charges plot")
gscat <- gscat + geom_smooth()
gscat
```  

In general, charges increase with age. There is no difference between the amount of money paid by men and women.  

```{r}
## scatter
gscat <- ggplot(medical_cost, aes(age, charges)) + geom_point()
gscat <- gscat + labs(title = "Age vs Charges plot")
gscat <- gscat + geom_smooth() + facet_grid(.~region)
gscat
```  

The tendency is the same when we plot the age vs charges by region. The older the person, the more money he/she spends on medical insurances.  

* ##### **BMI vs Charges**  

Again, let's make a plot of *BMI vs Charges*, discretizing by *sex*.  

```{r}
## scatter
gscat2 <- ggplot(medical_cost, aes(bmi, charges, color=sex)) + geom_point()
gscat2 <- gscat2 + labs(x="BMI", y="Charges", title="BMI vs Charges")
gscat2
```  

There is no a clear trend between the charges by BMI. BMI seems to be well distributed between both sex. Now, let't compare the amount paid by people with a BMI greater and less than the mean.  

```{r}
## bmi
medical_age$bmiAbvMean <- ifelse(medical_age$bmi>mean(medical_age$bmi), "Above", "Below")
medical_age$bmiAbvMean <- as.factor(medical_age$bmiAbvMean)

## plot
ghist <- ggplot(medical_age, aes(x=charges)) + geom_histogram(aes(color=bmiAbvMean, fill=bmiAbvMean))
ghist <- ghist + facet_grid(bmiAbvMean~.) + labs(title="Charges distribution by BMI", y="")
ghist

```  

The previous plot shows that the amount of money spent by people with a BMI above or below the mean doesn't vary a lot. Now I want to analyze it in terms of the *smoker* variable.  

```{r}
## smoke
gscat3 <- ggplot(medical_cost, aes(bmi, charges, color=smoker)) + geom_point()
gscat3 <- gscat3 + labs(x="BMI", y="Charges", title="BMI vs Charges")
gscat3

```  
Smokers spend more money in medical insurances regardless of their *BMI*. Now, let's see the average amount of money people paid according to their number of children.  

```{r}
## children

gbar <- ggplot(medical_cost, aes(x=children, y=charges)) + stat_summary(fun.y = "mean", geom = "bar", color="lightblue", fill="lightblue")
gbar <- gbar + labs(title="Average Charges by # of Children")
gbar
```  
Having more children doesn't mean people will spend more money in medical insurances. In fact, people with 5 children pay less money than the others.  

```{r}
gbox <- ggplot(medical_cost, aes(x=children, y=charges)) + geom_boxplot(aes(fill=children))
gbox <- gbox + labs(title="Charges by # of children")
gbox
```  

* As we see, in every case there are outliers in the money people with a certain amount of children paid.  
* The median charges (the line inside the box) is almost doesn't vary a lot in a scale of thousands.  
* The range of charges is wider in families with 2 and 3 children, which where found to spend more money in average (see previous plot).  

* **Charges by Sex**  

In this part, I want to observe the charges distribution by sex by drawing a *violin plot*.  

```{r}
#charges by sex
gvio <- ggplot(medical_cost, aes(x=charges, y=sex)) + geom_violin(aes(fill=sex))
gvio
```  

As we said earlier, there is not much difference between the average amount of money paid by each gender as is shown in the violin plot. 


### **Linear Model**  

From the previous plot, we saw a weak linear correlation between the continuous features and the target variable. Having that into account, I want to fit a Linear model with the `lm()` function to see the performance of this model. With those results, I want to see whether it is necessary to transform the variables in order to get a better performance.  

Now I'm going to train the linear model with all of the features.  


```{r}
## linear model
model_1 <- lm(charges~., data=medical_cost)
summary(model_1)
```  
From the obtained p-values, we can see that, in general, the region variable is not significant to the model.  
This model also shows a R2 equals to 74.97%, which is low in terms of the performance of the model when predicting. I will train a model without the intercept to figure out if the model improves.  

```{r}
## linear model 2
model_2 <- lm(charges~.-1, data=medical_cost)
summary(model_2)
```  
By removing the intercept we can observe that the model improves, since our R2 now is 88.62%. We can use this model to make predictions using the testing later in this notebook.  

For now, let's get some of the plots R allows us to draw in order to understand better our linear model.  

```{r}
## plots
par(mfrow=c(1,2))

plot(model_2,1)
plot(model_2,2)
```  

In the Residuals vs Fitted plot, we can observe that the point are not randomly distributed (the ideal behavior). In statistics this behavior is attributed to the fact that the variance of the error terms is not constant.  

```{r}
## plots
par(mfrow=c(1,2))

plot(model_2,3)
plot(model_2,4)
```  

The cook distance is a way to estimate the influence of a data point when performing a least-squared linear regression analysis like the one I'm trying to perform. This Cook's distance measures the effect of deleting a given point on the regression and in a deeper study it is good to examine those point with a high Cook's distance.   

Any point with a Cook's distance higher than 0.5 is consider to have a high influence on the model, so we don't have such a problem.  


```{r}
## plots
par(mfrow=c(1,2))

plot(model_2,5)
plot(model_2,6)
```  

The residuals vs leverage plot shows the Standarized Residuals. Here, any point above 2 and below -2 is suspicious to be an outlier. Our model also take 13 predictor (taking into account the codification it takes for the categorical ones), so any point with a leverage higher than ($2*13/1338 = 0.019$) is consider to have a high leverage.  

From the linear model, we can get the leverage, standarized residuals and Cook's distance by using some functions. I'm gonna do that and add each of these calculations to the dataset.  

```{r}
## new variables
medical_cost$Leverage <- hatvalues(model_2)
medical_cost$Stand.resid <- rstandard(model_2)
medical_cost$Cooks.dist <- cooks.distance(model_2)

head(medical_cost)
```  

We can identify the influential point by filtering the data set using the `which()` function.  

* **High residual point**  

```{r}
high_resid <- medical_cost[which(abs(medical_cost$Stand.resid)>2),]
head(high_resid)
```  

* **High leverage point**  

```{r}
num_coef = length(model_2$coefficients)
num_row = length(model_2$residuals)

high_leverage <- medical_cost[which(medical_cost$Leverage>(2*num_coef/num_row)), ]
head(high_leverage)
```  

* **High Cook's Distance Points**  

```{r}
medical_cost[which(medical_cost$Cooks.dist>0.5),]
```  

As we saw earlier, there are no points with a high Cook's distance.  

We can organize the influential points, having high leverage and high residual, in order to study them closely. To do this I'll use the `union()` function.  

```{r}
influentials <- union(which(medical_cost$Leverage>(2*num_coef/num_row)), which(abs(medical_cost$Stand.resid)>2))

influentials <- sort(influentials)

## dataset
influential_points <- medical_cost[influentials, ]
head(influential_points)
```  

With this data and more information about the source of the data one could perform a deeper analysis. That work is out of the scope of this analysis.  

From the previous analysis, we can say that the linear model may not be the adequate for predicting the Medical Insurances Cost. It could be a good idea to try fitting another model, but that's not the idea here; I just wanted to discover and understand some of the features related to performing an analysis using the *Linear Model*.  

































































